---
title: "Indicator Heterogeneity I: Temporal Heterogeneity"
author: "Addison"
output:
  html_document
---
```{r import_statements, echo = FALSE, message = FALSE}
library(tidyverse)
library(covidcast)
```

```{r setup_multidplyr, echo = TRUE}
PARCOMPUTE = TRUE
N_CORE = parallel::detectCores()
```

# Background

In this notebook, we repeat the analysis of `02_temporal_heterogeneity.Rmd`
for all of our core indicators.

# Data setup

```{r data_ingestion_county, echo = TRUE, cache=TRUE}
download_delayed_data = function(source_name,
                                 signal_name,
                                 start_day,
                                 end_day,
                                 geo_level,
                                 n_delay) {
  iterdays = 0:(end_day-start_day)
  if (!PARCOMPUTE) {
    lfunc = lapply
  } else {
    lfunc = function(x, f) { parallel::mclapply(x, f, mc.cores = N_CORE) }
  }
  bind_rows(lfunc(iterdays, function(dt) {
                      suppressWarnings(
                      covidcast_signal(source_name,
                                       signal_name,
                                       start_day+dt,
                                       start_day+dt,
                                       geo_type=geo_level,
                                       as_of=start_day+dt+n_delay))
  }))
}
# Fetch the following sources and signals from the API 
# TODO: Add Google Symptoms "eventually"
source_names = c("doctor-visits", "fb-survey", "fb-survey", "hospital-admissions")
signal_names = c("smoothed_adj_cli", "smoothed_cli", "smoothed_hh_cmnty_cli", 
            "smoothed_adj_covid19")
pretty_names = c("Doctor visits", "Facebook CLI", "Facebook CLI-in-community", 
          "Hospitalizations")
target_names = c("Cases", "Cases", "Cases", "Deaths")
geo_level = "county"

start_day = lubridate::ymd("2020-04-15")
end_day = lubridate::today()
n_delays = 1:14

for (n_delay in n_delays) {
  message(n_delay)
  cache_fname = sprintf('cached_data/05_delayed_indicators_d%02d.RDS',
                        n_delay)
  if (!file.exists(cache_fname)) {
    df_signals = vector("list", length(signal_names))
    for (ind_idx in 1:length(signal_names)) {
      df_signals[[ind_idx]] = download_delayed_data(source_names[ind_idx],
                                                    signal_names[ind_idx],
                                                    start_day,
                                                    end_day,
                                                    geo_level,
                                                    n_delay)
    }
    # Fetch USAFacts confirmed case incidence proportion (smoothed with 7-day 
    # trailing average)
    df_cases = download_delayed_data("usa-facts",
                                     "confirmed_7dav_incidence_prop",
                                     start_day,
                                     end_day,
                                     geo_level,
                                     n_delay)
    df_deaths = download_delayed_data("usa-facts",
                                     "deaths_7dav_incidence_prop",
                                     start_day,
                                     end_day,
                                     geo_level,
                                     n_delay)
    saveRDS(list(df_signals, df_cases, df_deaths), cache_fname)
  } else {
    cached_data = readRDS(cache_fname)
    df_signals = cached_data[[1]]
    df_cases = cached_data[[2]]
    df_deaths = cached_data[[3]]
  }
}
```

## Setup


TODO: update rest of this thing
```{r train_correlations, echo = TRUE}
sensorize_time_ranges = list(
      c(-7, 0),
      c(-10, 0),
      c(-14, 0),
      c(-21, 0))

# TODO: Add more "core indicators"

for (ind_idx in 1:length(source_names)) {
  if (target_names[ind_idx] == 'Cases') {
    df_target = df_cases
  } else if (target_names[ind_idx] == 'Deaths') {
    df_target = df_deaths
  } else {
    stop(sprintf("No matching dataframe for target %s.", target_names[ind_idx]))
  }
  ind_df = tibble(df_signals[[ind_idx]])
  ind_target = inner_join(ind_df, tibble(df_target),
                          by=c('geo_value', 'time_value')) %>% select (
        geo_value=geo_value,
        time_value=time_value,
        indicator_value=value.x,
        target_value=value.y,
      )
	ind_global_sensorized =  ind_target %>% group_by (
				geo_value,
			) %>% group_modify ( ~ {
				fit = lm(target_value ~ indicator_value, data =.x);
				tibble(time_value=.x$time_value,
							 indicator_value=.x$indicator_value,
							 target_value=.x$target_value,
							 sensorized_value=fit$fitted.values)
			}) %>% ungroup
	df_global_sensorized = ind_global_sensorized %>% transmute (
				geo_value=geo_value,
				signal='ind_sensorized',
				time_value=time_value,
				direction=NA,
				issue=lubridate::ymd('2020-11-01'),
				lag=NA,
				value=sensorized_value,
				stderr=NA,
				sample_size=NA,
				data_source='linear_sensorization',
			)
	attributes(df_global_sensorized)$geo_type = 'county'
	attributes(df_global_sensorized)$metadata$geo_type = 'county'
	class(df_global_sensorized) = c("covidcast_signal", "data.frame")

  base_cor_fname = sprintf('results/03_base_cors_%s_%s.RDS',
                            source_names[ind_idx], signal_names[ind_idx])
  if (!file.exists(base_cor_fname)) {
    df_cor_base_ind = covidcast_cor(df_signals[[ind_idx]], df_target,
                                   by='time_value', method='spearman')
    df_cor_sensorized_ind = covidcast_cor(df_global_sensorized, df_target,
                                         by='time_value', method='spearman')
    df_cor_base = rbind(df_cor_base_ind, df_cor_sensorized_ind)
    df_cor_base$Indicator = as.factor(c(rep('Raw', nrow(df_cor_base_ind)),
                                        rep('Sensorized (Spatial)',
                                            nrow(df_cor_sensorized_ind))))
    saveRDS(df_cor_base, base_cor_fname)
  } else {
    df_cor_base = readRDS(base_cor_fname)
  }



  sensorize_fname = sprintf('results/03_sensorize_cors_%s_%s.RDS',
                            source_names[ind_idx], signal_names[ind_idx])
  if (!file.exists(sensorize_fname)) {
    sensorize_cors = vector('list', length(sensorize_time_ranges))
    for (outer_idx in 1:length(sensorize_time_ranges)) {
      sensorize_llim = sensorize_time_ranges[[outer_idx]][1]
      sensorize_ulim = sensorize_time_ranges[[outer_idx]][2]

      min_sensorize_date = lubridate::ymd(start_day) - sensorize_llim
      max_sensorize_date = max(ind_target$time_value)
      sensorize_date_offsets = 0:(max_sensorize_date-min_sensorize_date)

      joiner_df_list = vector('list', length(sensorize_date_offsets))
      for (idx in 1:length(sensorize_date_offsets)) {
        dt = sensorize_date_offsets[idx]
        sensorize_date = min_sensorize_date + dt
        joiner_df_list[[idx]] = tibble(
                          sensorize_date = sensorize_date,
                          time_value = sensorize_date + sensorize_llim:sensorize_ulim)
      }
      joiner_df = bind_rows(joiner_df_list)

      if (!PARCOMPUTE) {
        ind_sensorized_lm =  ind_target %>% full_join(
              joiner_df,
              on='time_value',
            ) %>%  group_by (
              geo_value,
              sensorize_date,
            ) %>% group_modify (
              ~ broom::tidy(lm(target_value ~ indicator_value, data = .x))
            ) %>% ungroup
      } else {
        ind_grouped_list =   ind_target %>% full_join(
              joiner_df,
              on='time_value',
            ) %>%  group_by (
              geo_value,
              sensorize_date,
            ) %>% group_split
        ind_sensorized_lm = parallel::mclapply(ind_grouped_list, function(df) {
            broom::tidy(
              lm(target_value ~ indicator_value, data = df)
            ) %>% mutate (
              geo_value = unique(df$geo_value),
              sensorize_date = unique(df$sensorize_date),
            )}, mc.cores = N_CORE) %>% bind_rows
      }
      ind_sensorized_wide = ind_sensorized_lm %>% select(
            geo_value,
            sensorize_date,
            term,
            estimate,
          ) %>% mutate (
            term = sapply(term, function(x) {ifelse(x=='(Intercept)',
                                                    'intercept',
                                                    'slope')}),
          ) %>% pivot_wider (
            id_cols = c(geo_value, sensorize_date),
            names_from=term,
            values_from=estimate,
          )
      ind_target_sensorized = ind_target %>% inner_join (
            ind_sensorized_wide,
            by=c('time_value'='sensorize_date',
                 'geo_value'),
          ) %>% mutate (
            sensorized_value = intercept + indicator_value * slope,
          )
      df_sensorized = ind_target_sensorized %>% transmute (
            geo_value=geo_value,
            signal='ind_sensorized',
            time_value=time_value,
            direction=NA,
            issue=lubridate::ymd('2020-11-01'),
            lag=NA,
            value=sensorized_value,
            stderr=NA,
            sample_size=NA,
            data_source='linear_sensorization',
          )
      attributes(df_sensorized)$geo_type = 'county'
      class(df_sensorized) = c("covidcast_signal", "data.frame")

      df_cor_sensorized_ind = covidcast_cor(df_sensorized, df_target,
                                           by='time_value', method='spearman')
      df_cor_sensorized_ind$Indicator = sprintf('Sensorized (TS, %d:%d)',
                                               sensorize_llim,
                                               sensorize_ulim)
      sensorize_cors[[outer_idx]] = df_cor_sensorized_ind
    }

    saveRDS(sensorize_cors, sensorize_fname)
  } else {
    sensorize_cors = readRDS(sensorize_fname)
  }

  df_cor = bind_rows(df_cor_base, sensorize_cors)
  df_cor$Indicator = factor(df_cor$Indicator,
                            levels=c('Raw',
                                     'Sensorized (Spatial)',
                                     sapply(sensorize_time_ranges,
                                            function(x) {
                                              sprintf('Sensorized (TS, %d:%d)',
                                                      x[[1]], x[[2]])
                                            })))

  plt = ggplot(df_cor, aes(x = time_value, y = value)) +
    geom_line(aes(color = Indicator)) +
    labs(title = sprintf("Correlation between %s and %s",
                         pretty_names[ind_idx],
                         target_names[ind_idx]),
         subtitle = "Per day",
         x = "Date", y = "Correlation") +
    theme(legend.position = "bottom")
  print(plt)
}

```

