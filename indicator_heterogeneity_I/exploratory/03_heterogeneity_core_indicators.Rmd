---
title: "Indicator Heterogeneity I: Temporal Heterogeneity"
author: "Addison"
output:
  html_document
---
```{r import_statements, echo = FALSE, message = FALSE}
library(tidyverse)
library(covidcast)
```

```{r setup_multidplyr, echo = TRUE}
PARCOMPUTE = TRUE
N_CORE = parallel::detectCores()
```

# Background

In this notebook, we repeat the analysis of `02_temporal_heterogeneity.Rmd`
for all of our core indicators.

# Data setup

```{r data_ingestion_county, echo = TRUE, cache=TRUE}
# Fetch the following sources and signals from the API 
source_names = c("doctor-visits", "fb-survey", "fb-survey", "hospital-admissions")
signal_names = c("smoothed_adj_cli", "smoothed_cli", "smoothed_hh_cmnty_cli", 
            "smoothed_adj_covid19")
pretty_names = c("Doctor visits", "Facebook CLI", "Facebook CLI-in-community", 
          "Hospitalizations")
geo_level = "county"

start_day = "2020-04-15"
end_day = NULL
cache_fname = 'cached_data/02_temporal_heterogeneity.RDS'

if (!file.exists(cache_fname)) {
  df_signals = vector("list", length(signals))
  for (i in 1:length(signals)) {
    df_signals[[i]] = suppressWarnings(
                        covidcast_signal(sources[i], signals[i],
                                         start_day, end_day,
                                         geo_type=geo_level))
  }

  # Fetch USAFacts confirmed case incidence proportion (smoothed with 7-day 
  # trailing average)
  df_cases = suppressWarnings(
              covidcast_signal("usa-facts", "confirmed_7dav_incidence_prop",
                              start_day, end_day,
                              geo_type=geo_level))

  case_num = 500
  geo_values = suppressWarnings(covidcast_signal("usa-facts", "confirmed_cumulative_num",
                                max(df_cases$time_value), 
                                max(df_cases$time_value))) %>%
    filter(value >= case_num) %>% pull(geo_value)
  saveRDS(list(df_signals, df_cases), cache_fname)
} else {
  cached_data = readRDS(cache_fname)
  df_signals = cached_data[[1]]
  df_cases = cached_data[[2]]
}
```

## Setup

```{r train_correlations, echo = TRUE}
sensorize_time_ranges = list(
      c(-14, -1),
      c(-14, -5),
      c(-21, -1),
      c(-21, -5))
sensorize_cors = vector('list', length(sensorize_time_ranges))

for (ind_idx in 1:length(source_names)) {
  ind_df = tibble(df_signals[[ind_idx]])
  cases = tibble(df_cases)
  ind_cases = inner_join(ind_df, cases, by=c('geo_value', 'time_value')) %>% select (
        geo_value=geo_value,
        time_value=time_value,
        indicator_value=value.x,
        cases_value=value.y,
      )
  # TODO: Recompute these, but for all indicators too
  df_cor = readRDS('results/01_df_cor.RDS')
  for (outer_idx in 1:length(sensorize_time_ranges)) {
    sensorize_llim = sensorize_time_ranges[[outer_idx]][1]
    sensorize_ulim = sensorize_time_ranges[[outer_idx]][2]

    min_sensorize_date = lubridate::ymd(start_day) - sensorize_llim
    max_sensorize_date = max(ind_cases$time_value)
    sensorize_date_offsets = 0:(max_sensorize_date-min_sensorize_date)

    joiner_df_list = vector('list', length(sensorize_date_offsets))
    for (idx in 1:length(sensorize_date_offsets)) {
      dt = sensorize_date_offsets[idx]
      sensorize_date = min_sensorize_date + dt
      joiner_df_list[[idx]] = tibble(
                        sensorize_date = sensorize_date,
                        time_value = sensorize_date + sensorize_llim:sensorize_ulim)
    }
    joiner_df = bind_rows(joiner_df_list)

    if (!PARCOMPUTE) {
      ind_sensorized_lm =  ind_cases %>% full_join(
            joiner_df,
            on='time_value',
          ) %>%  group_by (
            geo_value,
            sensorize_date,
          ) %>% group_modify (
            ~ broom::tidy(lm(cases_value ~ indicator_value, data = .x))
          ) %>% ungroup
    } else {
      ind_grouped_list =   ind_cases %>% full_join(
            joiner_df,
            on='time_value',
          ) %>%  group_by (
            geo_value,
            sensorize_date,
          ) %>% group_split
      ind_sensorized_lm = parallel::mclapply(ind_grouped_list, function(df) {
          broom::tidy(
            lm(cases_value ~ indicator_value, data = df)
          ) %>% mutate (
            geo_value = unique(df$geo_value),
            sensorize_date = unique(df$sensorize_date),
          )}, mc.cores = N_CORE) %>% bind_rows
    }
    ind_sensorized_wide = ind_sensorized_lm %>% select(
          geo_value,
          sensorize_date,
          term,
          estimate,
        ) %>% mutate (
          term = sapply(term, function(x) {ifelse(x=='(Intercept)',
                                                  'intercept',
                                                  'slope')}),
        ) %>% pivot_wider (
          id_cols = c(geo_value, sensorize_date),
          names_from=term,
          values_from=estimate,
        )
    ind_cases_sensorized = ind_cases %>% inner_join (
          ind_sensorized_wide,
          by=c('time_value'='sensorize_date',
               'geo_value'),
        ) %>% mutate (
          sensorized_value = intercept + indicator_value * slope,
        )
    df_sensorized = ind_cases_sensorized %>% transmute (
          geo_value=geo_value,
          # TODO: update signal?
          signal='ind_sensorized',
          time_value=time_value,
          direction=NA,
          issue=lubridate::ymd('2020-11-01'),
          lag=NA,
          value=sensorized_value,
          stderr=NA,
          sample_size=NA,
          data_source='linear_sensorization',
        )
    attributes(df_sensorized)$geo_type = 'county'
    class(df_sensorized) = c("covidcast_signal", "data.frame")

    df_cor_sensorized_ind = covidcast_cor(df_sensorized, df_cases,
                                         by='time_value', method='spearman')
    df_cor_sensorized_ind$Indicator = sprintf('Sensorized (TS, %d:%d)',
                                             sensorize_llim,
                                             sensorize_ulim)
    sensorize_cors[[outer_idx]] = df_cor_sensorized_ind
  }

  # TODO update this
  saveRDS(sensorize_cors, sprintf('results/03_sensorize_cors_%s_%s.RDS',
                                  source_names[ind_idx], signal_names[ind_idx]))

  df_cor = bind_rows(df_cor_base, sensorize_cors)
  plt = ggplot(df_cor, aes(x = time_value, y = value)) +
    geom_line(aes(color = Indicator)) +
    # TODO :update to use indicator name
    labs(title = sprintf("Correlation between %s and cases",
                         fancy_names[ind_idx]),
         subtitle = "Per day",
         x = "Date", y = "Correlation") +
    theme(legend.position = "bottom")
  plt
}

```

