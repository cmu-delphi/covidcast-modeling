---
title: "Analysis of Variance on State-level Government Intervention"
author: "Kenneth Lee"
date: "15/09/2020"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: True
      smooth_scroll: True
---

## Data Preprocessing
```{r import packages, warning = FALSE, message = FALSE}
library(ggplot2)
library (readr)
library(tidyverse)
library(dplyr)
library(covidcast)
library(lubridate)
library(ggpubr)
library(reshape2)
library(tidyr)
library(viridis)
library(gridExtra)
library(zoo)
library(cowplot)
library(gplots)
library(car)

source("code/painter.r")
source("code/load_all_data.r")
```

```{r define global variables}
STARTDATE <- "2020-02-20"
ENDDATE <- lubridate::today()
GEO_TYPE = "state" # state-level
GEO_VALUE = "*" # all states
EXCLUDED_AREAS = c("as","gu", "mp","vi") # excluded areas due to small sample size
DT_X = 7 # 	 Time shifts to consider for x
```

```{r import data, warning = FALSE, message=FALSE}
data <- load_covidcast_data(STARTDATE, ENDDATE, GEO_TYPE, GEO_VALUE, EXCLUDED_AREAS)

# Read government intervention data
urlfile="https://raw.githubusercontent.com/COVID19StatePolicy/SocialDistancing/master/data/USstatesCov19distancingpolicy.csv"
policy <- read_csv(url(urlfile))

```

```{r preprocess policy data}
# Convert to lower case
policy$StatePostal <- tolower(policy$StatePostal)
# First we convert the date to a proper format
policy[, c("DateIssued", "DateEnacted", "DateExpiry" ,"DateEased", "DateEnded", "DateReexpanded1", "DateReeased1")] <- data.frame(lapply(policy[, c("DateIssued", "DateEnacted", "DateExpiry" ,"DateEased", "DateEnded", "DateReexpanded1", "DateReeased1")], function(x) as.Date(as.character(x), "%Y%m%d")))

# How many unique policy per state for each policy?
state.policy <- policy %>% filter(StateWide == 1)
```

## Explore the variability of policy across states

```{r Count of all policies}
# Plot for non-distinct count and mandate distribution
policy.by.state <- state.policy[,c("StateName","StatePolicy", "Mandate")]
# Get the count
new_counts <- table(policy.by.state$StatePolicy, policy.by.state$Mandate)

# Convert to data frame
new_counts.df <- as.data.frame(new_counts)
# Change the colname for the future legend readibility
colnames(new_counts.df)[2] <- "Mandate?"

# Plot the graph for the count
p <- ggplot(new_counts.df,aes(x= reorder(Var1,Freq),Freq)) +
  geom_bar(stat ="identity")+
  coord_flip()+
  labs(title = "Count of State-wide Policy Across States", y="Distinct Count", x="Policy")
p

# Show the difference by Mandate?
p <- ggplot(new_counts.df,aes(x= reorder(Var1,Freq),Freq, fill = `Mandate?`)) +
  geom_bar(stat ="identity")+
  coord_flip()+
  labs(title = "Count of State-wide Policy Across States", y="Distinct Count", x="Policy")+
   guides(fill=guide_legend(title="Mandate?"))
p

```

```{r Distinct count of policies}
# Filter the dataframe by distrinct rows
unique.policy.by.state <- distinct(state.policy[,c("StateName","StatePolicy")])
# Get the count
counts <- table(unique.policy.by.state$StatePolicy)

# Convert to data frame
counts.df <- as.data.frame(counts) 

# Rename the policy for better readibility
counts.df[,"Var1"] <- c("Bar restrictions", "Case-based isolation orders", "Emergency declarations", "Gathering Recommendations", "Gathering Restriction", "Non-essential business closures", "Other Business closures", "Public mask", "Travel-based quarantine order", "Restaurant restrictions", "School closures", "Stay-at-home order", "TravelRestrictEntry", "TravelRestrictExit", "TravelRestrictWithinState")
  
# Plot the graph for ditinct count
p <- ggplot(counts.df,aes(x= reorder(Var1,Freq),Freq, fill=Freq))+
  geom_bar(stat ="identity")+
  coord_flip()+
  labs(title = "Distinct Count of State-wide Policy Across States", y="Distinct Count", x="Policy")

p
```



## Construct government intervention signal over time

We may construct a simple signal to represent state-wide government intervention over time. To do so, we count the number of policies that has been enacted in a day and take the average number within 7 days as an intervention signal.

```{r construct government intervention signal}

# Get the dates between start and end date
all.dates <- seq(as.Date(STARTDATE), as.Date(ENDDATE), by="days")
time_value <- sort(rep(all.dates, length(unique(policy$StatePostal)) )) 

# Generate geo_value
geo_value <- rep(unique(policy$StatePostal), length(all.dates))
policy_signal <- data.frame(time_value = time_value, geo_value = geo_value)

# Create empty columns
policy_signal[,unique(policy$StatePolicy)] <- 0

# Fill in the count for each date
  # Get the policy name and state to filer policy signal 
for (row in (1:nrow(policy))){
  current.policy <- policy[row,]$StatePolicy
  current.state <- policy[row,]$StatePostal
  if (is.na(policy[row,]$DateEnded)){
    # Filter the rows of dataframe to be the current state and the time value that is after the policy is enacted.
    policy_signal[policy_signal$geo_value == current.state & policy_signal$time_value > as.Date(policy[row,]$DateEnacted), current.policy] <- 1
  }else{
    # Get time range between Date Enacted and Date Ended
    time.range <- seq(as.Date(policy[row,]$DateEnacted), as.Date(policy[row,]$DateEnded), by = "days")
    
    # Fill in the the rows that are in the current policy and fall between the time arrange to be 1
    policy_signal[policy_signal$time_value %in% time.range & policy_signal$geo_value == current.state, current.policy] <- 1
    }
}

# Compute the sum of the number of policies for every day in the state
policy_signal$total.num.policy <- rowSums(policy_signal[unique(policy$StatePolicy)])

# Compute the average on a 7day sliding window
policy_signal <-policy_signal %>%
    arrange(desc(geo_value)) %>% 
    group_by(geo_value) %>% 
    mutate(num.policy.7avg = rollmean(total.num.policy, k = 7, fill = NA))%>%
    ungroup()

# Finalize the covidcast-like signal for governemnt intervention
covidcast.like.policy.signal <- policy_signal %>% transmute(
  geo_value = geo_value,
  signal = "policy_7dav_num",
  time_value = time_value,
  direction = NA,
  issue = lubridate::today(),
  lag = issue - time_value,
  value = num.policy.7avg,
  stderr = NA,
  sample_size = NA,
  data_source = 'University of Washington')

# Pearson correlation between the number of policies and mobility across states
pearson_policy <- getCorrByShift(150, covidcast.like.policy.signal, data$Full.Time.Mobility, "pearson")

pearson_policy_med <-  getMedian(pearson_policy)

# plot the graph
p <- ggplot(pearson_policy_med , aes(x = dt, y = median)) + geom_line() + geom_point() + labs(title = "Median Pearson correlation between the number of policies and mobility", x = "Shift", y = "Correlation") +
  theme(legend.title = element_blank())

p

# Spearman correlation between the number of policies and mobility across states
spearman_policy <- getCorrByShift(150, covidcast.like.policy.signal,data$Full.Time.Mobility, "spearman")

spearman_policy_med <-  getMedian(spearman_policy)

s<- ggplot(spearman_policy_med, aes(x = dt, y = median)) + geom_line() + geom_point() + labs(title = "Median spearman correlation between the number of policies and mobility", x = "Shift", y = "Correlation") +
  theme(legend.title = element_blank())
s
```

## Correlation across states over different day shift 

```{r correlation based on different lags on multiple maps}
# Set a bunch of fields so that the data frame knows how to plot itself
ls = list()
idx <- seq(50,125,25)
count <- 1
for (i in idx){
  policy.mobility.cor <- covidcast_cor(covidcast.like.policy.signal, data$Full.Time.Mobility, by = "geo_value", dt_x = i, method = "spearman")

  policy.mobility.cor$time_value = STARTDATE
  policy.mobility.cor$issue = STARTDATE
  attributes(policy.mobility.cor)$geo_type = "state"
  class(policy.mobility.cor) = c("covidcast_signal", "data.frame")

# Plot choropleth maps, using the covidcast plotting functionality
ls[[count]]  <-plot(policy.mobility.cor, title = sprintf("%s-day shifted num of policies and mobility", i), range = c(-1, 1), choro_col = cm.colors(10), alpha = 0.4)
count <- count + 1
}

# Plot all graphs
do.call(grid.arrange,ls)
```

```{r combine intervention, mobility, cases, echo=FALSE}
# Intervention left join mobility
intervention_mobility <- left_join(data$Full.Time.Mobility,policy_signal, by=c("time_value", "geo_value"))

# Then we have the resutling df left join another cases dataframe
intervention_mobility_case <- left_join(intervention_mobility, data$Avg.Confirmed.Case.Count, by=c("time_value", "geo_value"))

# Change the categorical variable to be factor
factored_data <- cbind(intervention_mobility_case[1:10], lapply(intervention_mobility_case[11:25], as.factor),intervention_mobility_case[26:35])

# Filter state "pr" as it is not available in the intervention data
factored_data <- factored_data %>% filter(!(geo_value %in% c("pr")))
```

## Distribution of mobility by various intervention across states

```{r exploration, echo=FALSE}
# grouped boxplot
ggplot(factored_data, aes(x=value.x, y=geo_value, fill=BarRestrict)) + 
    geom_boxplot() +
  labs(title="Mobility by state and bar restriction",x="mobility", y="State")

# restaurant restriction
ggplot(factored_data, aes(x=value.x, y=geo_value, fill=RestaurantRestrict)) + 
    geom_boxplot() +
  labs(title="Mobility by state and restaurant restriction", x="mobility", y="State")

# Stay-at-home order
ggplot(factored_data, aes(x=value.x, y=geo_value, fill=
StayAtHome)) + 
    geom_boxplot() +
  labs(title="Mobility by state and stay-at-home order", x="mobility", y="State")

# Emergency declaration
ggplot(factored_data, aes(x=value.x, y=geo_value, fill=EmergDec)) + 
    geom_boxplot() +
  labs(title="Mobility by state and Emergency declaration", x="mobility", y="State")
```

## Treatment effect of government interventions

Moreover, we may be interested to know the following:

* Is there a difference in the means of mobility signal across state?

* Is there a difference in the means of mobility signal in terms of stay-at-home order?

* Is there an interaction between the factor of states and the factor of the order?

To answer these questions, assuming that the data are normally distributed and the variance across groups are homogeneous, we will use ANOVA (Analysis of Variance). We will check these assumptions in the model diagnostics. 


### Main effect of States

We can see that some states have a particularly higher range of the mean mobility signal. For example, Montana (MT) clearly stands out from the rest, whereas Hawaii (HI) has a much lower mean mobility signal from Feb. to Sep. in 2020.
h
```{r check main effect}
# Plotting the main effect of geo_value
plotmeans(value.x~geo_value,data=intervention_mobility_case, xlab="Geo_value", ylab="Mobility", main="Main effect (States)") 
```

### Correlation of the residuals from two linear regression models

```{r linear regression model}

# Plot the correlation between residuals given by two linear regression models

# model 0 : include only (X1) states, (X2) stayhome signal, (y) mobility
lm.fit.0 <- lm(value.x ~ as.factor(StayAtHome)+as.factor(geo_value), data=factored_data)
summary(lm.fit.0)

# model 1: include only (X1) states, (X2) cases signal, (y) mobility
lm.fit.1 <- lm(value.x ~ value.y+as.factor(geo_value), data=factored_data)
summary(lm.fit.1)

# Plot a scatter plot of the residual's correlation
plot(lm.fit.0$residuals, lm.fit.1$residuals)
```

### ANOVA

Due to the complexity of the model, we only select a model that includes up to all two-way interaction terms called model 4 and compare it with a model that doesn't include any interaction terms and call it model 3.

### Interpret the result

We can see that 

* Geo_value, Emergency declaration, and garthering restriction are statistically significant that would lead us to believe that these factors are associated with the mobility signal. 

* Internvation signals don't interact with each other significantly either. 

* The interaction between geo_value and gathering restriction has a largest sums of squares, it implies that the relationships between states and mobility depends on the emergency declariation.

```{r ANOVA table, echo=FALSE}
# Change the default setting for unbalanced ANOVA
options(contrasts = c("contr.sum", "contr.poly"))

# model 3: without interaction
model3 <- lm(value.x ~., data=factored_data[c("value.x","geo_value", "BarRestrict","OtherBusinessClose","RestaurantRestrict",  "StayAtHome", "EmergDec", "GathRestrict", "NEBusinessClose")])

# ANOVA test for unbalanced designs.
Anova(model3, type = "III")

# model 4: with interaction
model4 <- lm(value.x ~.^2, data=factored_data[c("value.x","geo_value", "BarRestrict","OtherBusinessClose","RestaurantRestrict",  "StayAtHome", "EmergDec", "GathRestrict", "NEBusinessClose")])

# print the ANOVA table
Anova(model4, singular.ok = T, type = "III") #set singular.ok = T to avoid error 
```

### Model diagnostics

* Homogenity of variance
  
  * We see the model hardly satisify this assumption. By the Levine's test, the variance across groups is statistically significantly different with the p-value is less than the significance level of 0.05. 

* Normality assumption
  
  * Visually, the normality assumption is roughly satisfied based on the normal qq plot. 

```{r model diagnostics, echo=FALSE}
# Model diagnoistics
par(mfrow=c(2,2))
plot(model3)
plot(model4)
par(mfrow=c(1,1))
```

```{r levine test, echo=FALSE}
leveneTest(value.x ~., data=factored_data[c("value.x","geo_value", "BarRestrict","OtherBusinessClose","RestaurantRestrict",  "StayAtHome", "EmergDec", "GathRestrict", "NEBusinessClose")])
```



